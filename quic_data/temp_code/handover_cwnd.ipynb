{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "database = \"/home/wmnlab/G/quic_data/\"\n",
    "dates = [\n",
    "    \"2024-07-04\",\n",
    "    \"2024-07-17\"\n",
    "]\n",
    "devices = sorted([\n",
    "    \"sm00\",\n",
    "    \"sm01\",\n",
    "])\n",
    "exps = {\n",
    "    \"QUIC-inf\": (3, [\"#{:02d}\".format(i + 1) for i in range(3)]),\n",
    "}\n",
    "\n",
    "exp_duration = 200\n",
    "data_len = 1223 \n",
    "time_data = exp_duration * 125000\n",
    "\n",
    "device_to_port = {\"sm00\": [5200, 5201], \n",
    "                  \"sm01\": [5202, 5203],\n",
    "                  \"sm02\": [5204, 5205],\n",
    "                  \"sm03\": [5206, 5207],\n",
    "                  \"sm04\": [5208, 5209],\n",
    "                  \"sm05\": [5210, 5211],\n",
    "                  \"sm06\": [5212, 5213],\n",
    "                  \"sm07\": [5214, 5215],\n",
    "                  \"sm08\": [5216, 5217],\n",
    "                  \"sm09\": [5218, 5219],\n",
    "                  \"MacBookProM1\": [4200, 4201],\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def find_ul_sent_file(database, date, exp, device):\n",
    "    ul_files = []\n",
    "    exp_rounds, exp_list = exps[exp]\n",
    "    ports = device_to_port.get(device, [])\n",
    "    for exp_round in exp_list:\n",
    "        folder_path = os.path.join(database, date, exp, device, exp_round, 'data')\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            file_pair = [\"\", \"\"]\n",
    "            for file in files:\n",
    "                if file.startswith(\"ul_processed_sent\"):\n",
    "                    file_pair[0] = os.path.join(root, file)\n",
    "                if file.startswith(\"ul_real_lost_pk\"):\n",
    "                    file_pair[1] = os.path.join(root, file)\n",
    "            ul_files.append(file_pair)\n",
    "    return ul_files\n",
    "\n",
    "def find_dl_sent_file(database, date, exp, device):\n",
    "    dl_files = []\n",
    "    exp_rounds, exp_list = exps[exp]\n",
    "    ports = device_to_port.get(device, [])\n",
    "    for exp_round in exp_list:\n",
    "        folder_path = os.path.join(database, date, exp, device, exp_round, 'data')\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            file_pair = [\"\", \"\"]\n",
    "            for file in files:\n",
    "                if file.startswith(\"dl_processed_sent\"):\n",
    "                    file_pair[0] = os.path.join(root, file)\n",
    "                if file.startswith(\"dl_real_lost_pk\"):\n",
    "                    file_pair[1] = os.path.join(root, file)\n",
    "            dl_files.append(file_pair)\n",
    "    return dl_files\n",
    "\n",
    "def find_ho_file(database, date, exp, device):\n",
    "    ho_files = []\n",
    "    exp_rounds, exp_list = exps[exp]\n",
    "    ports = device_to_port.get(device, [])\n",
    "    for exp_round in exp_list:\n",
    "        folder_path = os.path.join(database, date, exp, device, exp_round, 'data')\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            file_pair = [\"\", \"\", \"\"] # LTE, NR, handover_info_log\n",
    "            for file in files:\n",
    "                if file.startswith(\"handover_info_log\"):\n",
    "                    file_pair[0] = os.path.join(root, file)\n",
    "                if file.startswith(\"diag_log\") & file.endswith(\"_ml1.csv\"):\n",
    "                    if file.endswith(\"nr_ml1.csv\"):\n",
    "                        file_pair[2] = os.path.join(root, file)\n",
    "                    else:\n",
    "                        file_pair[1] = os.path.join(root, file)\n",
    "            ho_files.append(file_pair)\n",
    "    return ho_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def HoWithCwnd(ho_df, df):\n",
    "    df_events = pd.DataFrame(ho_df, columns=['start', 'end'])\n",
    "\n",
    "    # Ensure timestamps in df_events are in datetime format\n",
    "    df_events['start'] = pd.to_datetime(df_events['start'])\n",
    "    df_events['end'] = pd.to_datetime(df_events['end'].fillna(df_events['start']))\n",
    "\n",
    "    # Prepare the plot\n",
    "    fig, ax1 = plt.subplots(figsize=(50, 10))\n",
    "\n",
    "    # Plot congestion window with corrected Timestamp on the primary y-axis\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    ax1.plot(df['Timestamp'], df['congestion_window'], marker='o', markersize=2, color='green', label='Congestion Window')\n",
    "    ax1.set_xlabel('Timestamp')\n",
    "    ax1.set_ylabel('Congestion Window', color='green')\n",
    "    ax1.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "    # Create a secondary y-axis to plot the event rectangles\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylim(ax1.get_ylim())  # Match y-axis limits\n",
    "\n",
    "    # Draw rectangles for each event section\n",
    "    for _, event in df_events.iterrows():\n",
    "        start_time = event['start']\n",
    "        end_time = event['end']\n",
    "\n",
    "        # Add a rectangle for 1 second before the event start\n",
    "        rect_before = Rectangle((start_time - pd.Timedelta(seconds=5), -1), pd.Timedelta(seconds=5), 10, alpha=0.3, color='lightblue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect_before)\n",
    "\n",
    "        # Add a rectangle for the event duration (directly using datetime and Timedelta)\n",
    "        rect = Rectangle((start_time, -1), end_time - start_time, 10, alpha=0.5, color='blue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect)\n",
    "\n",
    "        # Add a rectangle for 1 second after the event end\n",
    "        rect_after = Rectangle((end_time, -1), pd.Timedelta(seconds=5), 10, alpha=0.3, color='lightblue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect_after)\n",
    "        \n",
    "    ax1.set_xlim(df_events['start'].min() - pd.Timedelta(seconds=5), df_events['end'].max() + pd.Timedelta(seconds=5))\n",
    "    ax2.set_ylim(0, 2.5)  # Set y-limits to ensure rectangles fit well in the plot\n",
    "\n",
    "    # Set labels and title\n",
    "    ax1.set_ylabel('Congestion Window', color='green')\n",
    "    ax1.set_title(\"Congestion Window & Handover Events\")\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def CwndWithPkl(df, lost_df):\n",
    "    # Create a plot with events marked on the x-axis\n",
    "    plt.figure(figsize=(50, 10))\n",
    "\n",
    "    # Set x-axis as timestamp\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Timestamp')\n",
    "\n",
    "    # Adding vertical lines for lost packets\n",
    "    for _, row in lost_df.iterrows():\n",
    "        lost_time = row['Timestamp']\n",
    "        plt.axvline(x=lost_time, color='brown', linestyle='--', label='Lost Packet')\n",
    "\n",
    "    # Plot the congestion window\n",
    "    plt.plot(df['Timestamp'], df['congestion_window'], marker='o', markersize=0.5, color='green', label='Congestion Window')\n",
    "\n",
    "    plt.title(\"Congestion Window & Packet Loss\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{figure_path}/pkl_cwnd_{time}_{port}.png\")\n",
    "    plt.show()\n",
    "\n",
    "def RttWithLenWithPkl(df, lost_df, time, port):\n",
    "    # Set the figure size to make the plot wider\n",
    "    fig, ax1 = plt.subplots(figsize=(50, 10))\n",
    "    # Plot the 'congestion_window' column on the primary y-axis\n",
    "\n",
    "    color2 = 'tab:blue'\n",
    "    ax1.set_ylim(0, 300)\n",
    "    ax1.set_ylabel('Latest RTT', color=color2)\n",
    "    ax1.plot(df['timestamp'], df['latest_rtt'], marker='s', markersize=1, color=color2, label='latest_rtt')\n",
    "    ax1.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    # Plot the 'length' on the secondary y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    color3 = 'tab:green'\n",
    "    ax2.plot(df['timestamp'], df['length'], marker='s', markersize=1, color=color3, label='length')\n",
    "    ax2.tick_params(axis='y', labelcolor=color3)\n",
    "\n",
    "    # Adding vertical lines for lost packets\n",
    "    for _, row in lost_df.iterrows():\n",
    "        lost_time = row['timestamp']\n",
    "        plt.axvline(x=lost_time, color='brown', linestyle='--', label='Lost Packet')\n",
    "\n",
    "    # Set title\n",
    "    plt.title(\"RTT & Stream Length & Packet Loss\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{figure_path}/rtt_length_{time}_{port}.png\")\n",
    "    plt.show()\n",
    "\n",
    "def HoWithPkl(ordered_HOs, lost_df, time, port, comment):\n",
    "    # Convert the list to a DataFrame\n",
    "    # df_events = pd.DataFrame(ordered_HOs, columns=['Event', 'Start Time', 'End Time'])\n",
    "    df_events = pd.DataFrame(ordered_HOs, columns=['Start Time', 'End Time'])\n",
    "\n",
    "    # Extract timestamp information from HO and MR objects\n",
    "    df_events['Start Time'] = df_events['Start Time'].apply(lambda x: x.start if hasattr(x, 'start') else (x.time if hasattr(x, 'time') else None))\n",
    "    df_events['End Time'] = df_events['End Time'].apply(lambda x: x.end if hasattr(x, 'end') else (x.time if hasattr(x, 'time') else None))\n",
    "\n",
    "    df_events['Start Time'] = pd.to_datetime(df_events['Start Time'])\n",
    "    df_events['End Time'] = pd.to_datetime(df_events['End Time'].fillna(df_events['Start Time']))\n",
    "\n",
    "    # Create a plot with events marked on the x-axis\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.plot(df_events['Start Time'], [0] * len(df_events), 'o', label='Start Time', markersize=2)\n",
    "    plt.plot(df_events['End Time'], [1] * len(df_events), 'o', label='End Time', markersize=2)\n",
    "\n",
    "    # Set x-axis as timestamp\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Timestamp')\n",
    "\n",
    "    # Add event labels\n",
    "    # for i, event in df_events.iterrows():\n",
    "    #     plt.text(event['Start Time'], 0, f'{event[\"Event\"]} (Start)', fontsize=8, ha='right')\n",
    "    #     plt.text(event['End Time'], 1, f'{event[\"Event\"]} (End)', fontsize=8, ha='right')\n",
    "\n",
    "    # Draw rectangles for each section\n",
    "    for _, event in df_events.iterrows():\n",
    "        start_time = event['Start Time']\n",
    "        end_time = event['End Time']\n",
    "\n",
    "        # Add a rectangle for 1 second before the event start\n",
    "        rect_before = Rectangle((start_time - pd.Timedelta(seconds=1), -0.5), pd.Timedelta(seconds=1), 5, alpha=0.5, color='lightblue')\n",
    "        plt.gca().add_patch(rect_before)\n",
    "\n",
    "        # Add a rectangle for the event duration\n",
    "        rect = Rectangle((start_time, -0.5), end_time - start_time, 5, alpha=1, color='blue')\n",
    "        plt.gca().add_patch(rect)\n",
    "\n",
    "        # Add a rectangle for 1 second after the event end\n",
    "        rect_after = Rectangle((end_time, -0.5), pd.Timedelta(seconds=1), 5, alpha=0.5, color='lightblue')\n",
    "        plt.gca().add_patch(rect_after)\n",
    "\n",
    "    # Adding vertical lines for lost packets\n",
    "    for _, row in lost_df.iterrows():\n",
    "        if row['trigger'] == \"time_threshold\":\n",
    "            lost_time = row['timestamp']\n",
    "            plt.axvline(x=lost_time, color='brown', linestyle='--', label='Lost Packet')\n",
    "        else:\n",
    "            lost_time = row['timestamp']\n",
    "            plt.axvline(x=lost_time, color='coral', linestyle='--', label='Lost Packet')\n",
    "        \n",
    "\n",
    "    plt.title(f\"Handover & Packet Loss\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{figure_path}/{comment}ho_timeline_{time}_{port}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for exp in exps:\n",
    "    for date in dates:\n",
    "        for device in devices:\n",
    "            ho_files = find_ho_file(database, date, exp, device)\n",
    "            ul_sent_files = find_ul_sent_file(database, date, exp, device)\n",
    "            dl_sent_files = find_dl_sent_file(database, date, exp, device)\n",
    "            for i, ul_file_pair in enumerate(ul_sent_files):\n",
    "                print(ul_file_pair)\n",
    "                ho_df = pd.read_csv(ho_files[i], sep=',')\n",
    "                ul_sent_df = pd.read_csv(ul_file_pair[0], sep='@')\n",
    "                ul_lost_df = pd.read_csv(ul_file_pair[1], sep=',')\n",
    "                HoWithCwnd(ho_df, ul_sent_df)\n",
    "            for i, dl_file_pair in enumerate(dl_sent_files):\n",
    "                print(dl_file_pair)\n",
    "                ho_df = pd.read_csv(ho_files[i], sep=',')\n",
    "                dl_sent_df = pd.read_csv(dl_file_pair[0], sep='@')\n",
    "                dl_lost_df = pd.read_csv(dl_file_pair[1], sep=',')\n",
    "                HoWithCwnd(ho_df, dl_sent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def filter_rows_around_event(sent_df, event):\n",
    "    # Ensure the Timestamp column is in datetime format\n",
    "    sent_df.loc[:, 'Timestamp'] = pd.to_datetime(sent_df.loc[:, 'Timestamp'])\n",
    "\n",
    "    # Extract event start and end times\n",
    "    start_time = pd.to_datetime(event['start'])\n",
    "    end_time = pd.to_datetime(event['end'])\n",
    "\n",
    "    # Compute the range for filtering\n",
    "    start_range = start_time - pd.Timedelta(seconds=5)\n",
    "    end_range = end_time + pd.Timedelta(seconds=5)\n",
    "\n",
    "    # Filter the DataFrame based on the computed range\n",
    "    filtered_df = sent_df[(sent_df.loc[:, 'Timestamp'] >= start_range) & (sent_df.loc[:, 'Timestamp'] <= end_range)]\n",
    "\n",
    "    filtered_df.reset_index()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def HoWithCwndRsrp(ho_df, df):\n",
    "    df_events = pd.DataFrame(ho_df, columns=['start', 'end', 'lte', 'nr'])\n",
    "\n",
    "    # Ensure timestamps in df_events are in datetime format\n",
    "    df_events['start'] = pd.to_datetime(df_events['start'])\n",
    "    df_events['end'] = pd.to_datetime(df_events.loc[:, 'end'].fillna(df_events['start']))\n",
    "    df_events['lte'].iloc[0]['Timestamp'] = pd.to_datetime(df_events['lte'].iloc[0]['Timestamp'])\n",
    "    df_events['nr'].iloc[0]['Timestamp'] = pd.to_datetime(df_events['nr'].iloc[0]['Timestamp'])\n",
    "\n",
    "    # Prepare the plot\n",
    "    fig, ax1 = plt.subplots(figsize=(30, 10))\n",
    "\n",
    "    # Plot congestion window with corrected Timestamp on the primary y-axis\n",
    "    df.loc[:, 'Timestamp'] = pd.to_datetime(df.loc[:, 'Timestamp'])\n",
    "    ax1.plot(df['Timestamp'], df['congestion_window'], marker='o', markersize=2, color='green', label='Congestion Window')\n",
    "    ax1.set_xlabel('Timestamp')\n",
    "    ax1.set_ylabel('Congestion Window', color='green')\n",
    "    ax1.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "    # Create a secondary y-axis to plot the event rectangles\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Create a third y-axis\n",
    "    ax3 = ax1.twinx()\n",
    "    ax3.plot(df_events['nr'].iloc[0]['Timestamp'], df_events['nr'].iloc[0]['RSRP0'], color='pink', label='RSRP', linewidth=2)\n",
    "    ax3.plot(df_events['lte'].iloc[0]['Timestamp'], df_events['lte'].iloc[0]['RSRP(dBm)'], color='orange', label='RSRP', linewidth=2)\n",
    "    ax3.set_ylabel('RSRP', color='orange')\n",
    "    ax3.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "    # Draw rectangles for each event section\n",
    "    for _, event in df_events.iterrows():\n",
    "        start_time = event['start']\n",
    "        end_time = event['end']\n",
    "\n",
    "        # Add a rectangle for 1 second before the event start\n",
    "        rect_before = Rectangle((start_time - pd.Timedelta(seconds=5), -1), pd.Timedelta(seconds=5), 10, alpha=0.3, color='lightblue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect_before)\n",
    "\n",
    "        # Add a rectangle for the event duration (directly using datetime and Timedelta)\n",
    "        rect = Rectangle((start_time, -1), end_time - start_time, 10, alpha=0.5, color='blue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect)\n",
    "\n",
    "        # Add a rectangle for 1 second after the event end\n",
    "        rect_after = Rectangle((end_time, -1), pd.Timedelta(seconds=5), 10, alpha=0.3, color='lightblue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect_after)\n",
    "        \n",
    "    ax1.set_xlim(df_events['start'].min() - pd.Timedelta(seconds=5), df_events['end'].max() + pd.Timedelta(seconds=5))\n",
    "    ax2.set_ylim(0, 2.5)  # Set y-limits to ensure rectangles fit well in the plot\n",
    "    ax2.set_yticks([])  # Removes the ticks on the y-axis\n",
    "    ax2.set_yticklabels([])  # Removes the labels on the y-axis\n",
    "    # Set labels and title\n",
    "    ax1.set_ylabel('Congestion Window', color='green')\n",
    "    ax1.set_title(\"Congestion Window & Handover Events\")\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def HoWithCwndRsrq(ho_df, df):\n",
    "    df_events = pd.DataFrame(ho_df, columns=['start', 'end', 'lte', 'nr'])\n",
    "\n",
    "    # Ensure timestamps in df_events are in datetime format\n",
    "    df_events['start'] = pd.to_datetime(df_events['start'])\n",
    "    df_events['end'] = pd.to_datetime(df_events.loc[:, 'end'].fillna(df_events['start']))\n",
    "    df_events['lte'].iloc[0]['Timestamp'] = pd.to_datetime(df_events['lte'].iloc[0]['Timestamp'])\n",
    "    df_events['nr'].iloc[0]['Timestamp'] = pd.to_datetime(df_events['nr'].iloc[0]['Timestamp'])\n",
    "\n",
    "    # Prepare the plot\n",
    "    fig, ax1 = plt.subplots(figsize=(30, 10))\n",
    "\n",
    "    # Plot congestion window with corrected Timestamp on the primary y-axis\n",
    "    df.loc[:, 'Timestamp'] = pd.to_datetime(df.loc[:, 'Timestamp'])\n",
    "    ax1.plot(df['Timestamp'], df['congestion_window'], marker='o', markersize=2, color='green', label='Congestion Window')\n",
    "    ax1.set_xlabel('Timestamp')\n",
    "    ax1.set_ylabel('Congestion Window', color='green')\n",
    "    ax1.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "    # Create a secondary y-axis to plot the event rectangles\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Create a third y-axis\n",
    "    ax3 = ax1.twinx()\n",
    "    ax3.plot(df_events['nr'].iloc[0]['Timestamp'], df_events['nr'].iloc[0]['RSRQ0'], color='pink', label='RSRQ (NR)', linewidth=2)\n",
    "    ax3.plot(df_events['lte'].iloc[0]['Timestamp'], df_events['lte'].iloc[0]['RSRQ(dB)'], color='orange', label='RSRQ', linewidth=2)\n",
    "    ax3.set_ylabel('RSRQ', color='orange')\n",
    "    ax3.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "    # Draw rectangles for each event section\n",
    "    for _, event in df_events.iterrows():\n",
    "        start_time = event['start']\n",
    "        end_time = event['end']\n",
    "\n",
    "        # Add a rectangle for 1 second before the event start\n",
    "        rect_before = Rectangle((start_time - pd.Timedelta(seconds=5), -1), pd.Timedelta(seconds=5), 10, alpha=0.3, color='lightblue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect_before)\n",
    "\n",
    "        # Add a rectangle for the event duration (directly using datetime and Timedelta)\n",
    "        rect = Rectangle((start_time, -1), end_time - start_time, 10, alpha=0.5, color='blue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect)\n",
    "\n",
    "        # Add a rectangle for 1 second after the event end\n",
    "        rect_after = Rectangle((end_time, -1), pd.Timedelta(seconds=5), 10, alpha=0.3, color='lightblue', transform=ax2.transData)\n",
    "        ax2.add_patch(rect_after)\n",
    "        \n",
    "    ax1.set_xlim(df_events['start'].min() - pd.Timedelta(seconds=5), df_events['end'].max() + pd.Timedelta(seconds=5))\n",
    "    ax2.set_ylim(0, 2.5)  # Set y-limits to ensure rectangles fit well in the plot\n",
    "    ax2.set_yticks([])  # Removes the ticks on the y-axis\n",
    "    ax2.set_yticklabels([])  # Removes the labels on the y-axis\n",
    "    # Set labels and title\n",
    "    ax1.set_ylabel('Congestion Window', color='green')\n",
    "    ax1.set_title(\"Congestion Window & Handover Events\")\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ho_dict = {'MNBH': [], 'SCGM': [], 'MCGF': [], 'SCGF': []}\n",
    "for exp in exps:\n",
    "    for date in dates:\n",
    "        for device in devices:\n",
    "            ho_files = find_ho_file(database, date, exp, device)\n",
    "            for file_pair in ho_files:\n",
    "                ho_df = pd.read_csv(file_pair[0], sep=',')\n",
    "                lte_df = pd.read_csv(file_pair[1], sep=',')\n",
    "                nr_df = pd.read_csv(file_pair[2], sep=',')\n",
    "                mnbh_df = ho_df[ho_df['type'] == 'MNBH']\n",
    "                for _, event in mnbh_df.iterrows():\n",
    "                    event['device'] = device\n",
    "                    lte_filtered_df = filter_rows_around_event(lte_df, event)\n",
    "                    event['lte'] = [lte_filtered_df]\n",
    "                    nr_filtered_df = filter_rows_around_event(nr_df, event)\n",
    "                    event['nr'] = [nr_filtered_df]\n",
    "                    ho_dict['MNBH'].append(event.to_dict())\n",
    "                scgm_df = ho_df[ho_df['type'] == 'SCGM']\n",
    "                for _, event in scgm_df.iterrows():\n",
    "                    event['device'] = device\n",
    "                    lte_filtered_df = filter_rows_around_event(lte_df, event)\n",
    "                    event['lte'] = [lte_filtered_df]\n",
    "                    nr_filtered_df = filter_rows_around_event(nr_df, event)\n",
    "                    event['nr'] = [nr_filtered_df]\n",
    "                    ho_dict['SCGM'].append(event.to_dict())\n",
    "                mcgf_df = ho_df[ho_df['type'] == 'MCGF']\n",
    "                for _, event in mcgf_df.iterrows():\n",
    "                    event['device'] = device\n",
    "                    lte_filtered_df = filter_rows_around_event(lte_df, event)\n",
    "                    event['lte'] = [lte_filtered_df]\n",
    "                    nr_filtered_df = filter_rows_around_event(nr_df, event)\n",
    "                    event['nr'] = [nr_filtered_df]\n",
    "                    ho_dict['MCGF'].append(event.to_dict())\n",
    "                scgf_df = ho_df[ho_df['type'] == 'SCGF']\n",
    "                for _, event in scgf_df.iterrows():\n",
    "                    event['device'] = device\n",
    "                    lte_filtered_df = filter_rows_around_event(lte_df, event)\n",
    "                    event['lte'] = [lte_filtered_df]\n",
    "                    nr_filtered_df = filter_rows_around_event(nr_df, event)\n",
    "                    event['nr'] = [nr_filtered_df]\n",
    "                    ho_dict['SCGF'].append(event.to_dict())\n",
    "\n",
    "print(\"MNBH:\", len(ho_dict['MNBH']), \"SCGM:\", len(ho_dict['SCGM']), \"MCGF:\", len(ho_dict['MCGF']), \"SCGF:\", len(ho_dict['SCGF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "all_dl_sent_df = None\n",
    "dl_sent_dfs = []\n",
    "for exp in exps:\n",
    "    for date in dates:\n",
    "        for device in devices:\n",
    "            # ul_sent_files = find_ul_sent_file(database, date, exp, device)\n",
    "            dl_sent_files = find_dl_sent_file(database, date, exp, device)\n",
    "            for file_pair in dl_sent_files:\n",
    "                dl_sent_df = pd.read_csv(file_pair[0], sep='@')\n",
    "                dl_sent_df['device'] = device\n",
    "                dl_sent_dfs.append(dl_sent_df)\n",
    "\n",
    "all_dl_sent_df = pd.concat(dl_sent_dfs, ignore_index=True)\n",
    "all_dl_sent_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for i in range(50, 60):\n",
    "    dl_sent_df = all_dl_sent_df[all_dl_sent_df['device'] == ho_dict['MNBH'][i]['device']]\n",
    "    filtered_df = filter_rows_around_event(dl_sent_df, ho_dict['MNBH'][i])\n",
    "    event_df = pd.DataFrame(ho_dict['MNBH'][i], index=[0])\n",
    "    # HoWithCwnd(event_df, filtered_df)\n",
    "    HoWithCwndRsrq(event_df, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for i in range(50, 55):\n",
    "    dl_sent_df = all_dl_sent_df[all_dl_sent_df['device'] == ho_dict['SCGM'][i]['device']]\n",
    "    filtered_df = filter_rows_around_event(dl_sent_df, ho_dict['SCGM'][i])\n",
    "    event_df = pd.DataFrame(ho_dict['SCGM'][i], index=[0])\n",
    "    # HoWithCwnd(event_df, filtered_df)\n",
    "    HoWithCwndRsrq(event_df, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    dl_sent_df = all_dl_sent_df[all_dl_sent_df['device'] == ho_dict['MCGF'][i]['device']]\n",
    "    filtered_df = filter_rows_around_event(dl_sent_df, ho_dict['MCGF'][i])\n",
    "    event_df = pd.DataFrame(ho_dict['MCGF'][i], index=[0])\n",
    "    # HoWithCwnd(event_df, filtered_df)\n",
    "    HoWithCwndRsrq(event_df, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "mcgf_lost_list = []\n",
    "for i in range(len(ho_dict['MCGF'])):\n",
    "    dl_sent_df = all_dl_sent_df[all_dl_sent_df['device'] == ho_dict['MCGF'][i]['device']]\n",
    "    filtered_df = filter_rows_around_event(dl_sent_df, ho_dict['MCGF'][i])\n",
    "    # for _, row in filtered_df.iterrows():\n",
    "    #     if pd.isna(row['congestion_window']):\n",
    "    #         print(\"yesy\")\n",
    "    #         break\n",
    "    # event_df = pd.DataFrame(ho_dict['MCGF'][i], index=[0])\n",
    "    # Identify the NaN values and calculate the length of consecutive NaNs\n",
    "    filtered_df.loc[:, 'is_nan'] = filtered_df['congestion_window'].isna()\n",
    "    filtered_df.loc[:, 'nan_group'] = filtered_df['is_nan'].cumsum()\n",
    "    filtered_df.loc[:, 'nan_streak'] = filtered_df.groupby((filtered_df['is_nan'] != filtered_df['is_nan'].shift()).cumsum())['is_nan'].transform('sum')\n",
    "    # Find the largest NaN streak\n",
    "    largest_nan_streak = filtered_df[filtered_df['is_nan']]['nan_streak'].max()\n",
    "    # Extract timestamps associated with the largest NaN streak\n",
    "    timestamps_largest_nan_streak = filtered_df[(filtered_df['is_nan']) & (filtered_df['nan_streak'] == largest_nan_streak)]['Timestamp']\n",
    "\n",
    "    # Calculate the time difference\n",
    "    if len(timestamps_largest_nan_streak) > 1:\n",
    "        time_diff = timestamps_largest_nan_streak.max() - timestamps_largest_nan_streak.min()\n",
    "    else:\n",
    "        time_diff = pd.Timedelta(0)\n",
    "\n",
    "    # Get the index of the first and last NaN in the largest streak\n",
    "    largest_nan_streak_idx = filtered_df[(filtered_df['is_nan']) & (filtered_df['nan_streak'] == largest_nan_streak)].index\n",
    "    # Get congestion_window values before and after the largest NaN streak\n",
    "    before_nan_value = after_nan_value = None\n",
    "    if not largest_nan_streak_idx.empty and largest_nan_streak_idx.min() > filtered_df.index[0]:\n",
    "        try:\n",
    "            before_nan_value = filtered_df.loc[largest_nan_streak_idx.min() - 1, 'congestion_window']\n",
    "        except:\n",
    "            before_nan_value = None\n",
    "    if not largest_nan_streak_idx.empty and largest_nan_streak_idx.max() < filtered_df.index[-1]:\n",
    "        try:\n",
    "            after_nan_value = filtered_df.loc[largest_nan_streak_idx.max() + 1, 'congestion_window']\n",
    "        except:\n",
    "            after_nan_value = None\n",
    "\n",
    "    if not before_nan_value == None and not after_nan_value == None:\n",
    "        cwnd_diff_ratio = (before_nan_value - after_nan_value) * 100 / before_nan_value\n",
    "    else:\n",
    "        cwnd_diff_ratio = None\n",
    "    \n",
    "    # print(before_nan_value, after_nan_value, cwnd_diff_ratio)\n",
    "    mcgf_lost_list.append([largest_nan_streak, time_diff, before_nan_value, after_nan_value, cwnd_diff_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "mcgf_lost_df = pd.DataFrame(mcgf_lost_list, columns=['lost_pkt_cnt', 'lost_pkt_interval', 'cwnd_before', 'cwnd_after', 'cwnd_diff_ratio'])\n",
    "lost_pkt_cnt_stats = mcgf_lost_df['lost_pkt_cnt'].describe()\n",
    "lost_pkt_interval_stats = mcgf_lost_df['lost_pkt_interval'].describe()\n",
    "cwnd_diff_ratio_stats = mcgf_lost_df['cwnd_diff_ratio'].describe()\n",
    "print(lost_pkt_cnt_stats)\n",
    "print(lost_pkt_interval_stats)\n",
    "print(cwnd_diff_ratio_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with timestamps\n",
    "data = {\n",
    "    'timestamp': pd.date_range(start='2023-01-01', periods=10, freq='T'),\n",
    "    'congestion_window': [1.2, None, None, 2.3, None, None, 3.4, None, None, 4.5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identify the NaN values and calculate the length of consecutive NaNs\n",
    "df['is_nan'] = df['congestion_window'].isna()\n",
    "df['nan_group'] = df['is_nan'].cumsum()\n",
    "df['nan_streak'] = df.groupby((df['is_nan'] != df['is_nan'].shift()).cumsum())['is_nan'].transform('sum')\n",
    "print(df)\n",
    "# Find the largest NaN streak\n",
    "largest_nan_streak = df[df['is_nan']]['nan_streak'].max()\n",
    "\n",
    "# Extract timestamps associated with the largest NaN streak\n",
    "timestamps_largest_nan_streak = df[(df['is_nan']) & (df['nan_streak'] == largest_nan_streak)]['timestamp']\n",
    "\n",
    "# Calculate the time difference\n",
    "if len(timestamps_largest_nan_streak) > 1:\n",
    "    time_diff = timestamps_largest_nan_streak.max() - timestamps_largest_nan_streak.min()\n",
    "else:\n",
    "    time_diff = pd.Timedelta(0)\n",
    "\n",
    "print(\"The largest number of consecutive NaN values is:\", largest_nan_streak)\n",
    "print(\"Timestamps associated with the largest NaN streak:\")\n",
    "print(timestamps_largest_nan_streak)\n",
    "print(\"Time difference between the first and last timestamp:\", time_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    dl_sent_df = all_dl_sent_df[all_dl_sent_df['device'] == ho_dict['SCGF'][i]['device']]\n",
    "    filtered_df = filter_rows_around_event(dl_sent_df, ho_dict['SCGF'][i])\n",
    "    event_df = pd.DataFrame(ho_dict['SCGF'][i], index=[0])\n",
    "    # HoWithCwnd(event_df, filtered_df)\n",
    "    HoWithCwndRsrq(event_df, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moxa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
