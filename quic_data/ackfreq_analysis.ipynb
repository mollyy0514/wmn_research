{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an experiment with `packetsBeforeAck = 2, 10, 15`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "database = \"/home/wmnlab/G/quic_data/\"\n",
    "dates = [\n",
    "    # \"2024-07-29\",\n",
    "    # \"2024-07-30\",\n",
    "    \"2024-08-04\"\n",
    "]\n",
    "devices = sorted([\n",
    "    \"sm00\",\n",
    "    \"sm01\",\n",
    "    \"sm02\",\n",
    "    \"sm03\",\n",
    "    # \"sm08\",\n",
    "    # \"MacBookProM1\",\n",
    "])\n",
    "exps = {\n",
    "    \"QUIC-ack1\": (2, [\"#{:02d}\".format(i + 1) for i in range(2)]),\n",
    "    \"QUIC-ack2\": (2, [\"#{:02d}\".format(i + 1) for i in range(2)]),\n",
    "    \"QUIC-ack10\": (2, [\"#{:02d}\".format(i + 1) for i in range(2)]),\n",
    "    \"QUIC-ack15\": (2, [\"#{:02d}\".format(i + 1) for i in range(2)]),\n",
    "}\n",
    "\n",
    "exp_duration = 200\n",
    "data_len = 1223 \n",
    "time_data = exp_duration * 125000\n",
    "\n",
    "device_to_port = {\"sm00\": [5200, 5201], \n",
    "                  \"sm01\": [5202, 5203],\n",
    "                  \"sm02\": [5204, 5205],\n",
    "                  \"sm03\": [5206, 5207],\n",
    "                  \"sm04\": [5208, 5209],\n",
    "                  \"sm05\": [5210, 5211],\n",
    "                  \"sm06\": [5212, 5213],\n",
    "                  \"sm07\": [5214, 5215],\n",
    "                  \"sm08\": [5216, 5217],\n",
    "                  \"sm09\": [5218, 5219],\n",
    "                  \"MacBookProM1\": [4200, 4201],\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def find_raw_files(database, date, exp, device):\n",
    "    exp_files_list = []\n",
    "    exp_rounds, exp_list = exps[exp]\n",
    "    ports = device_to_port.get(device, [])\n",
    "    for exp_round in exp_list:\n",
    "        folder_path = os.path.join(database, date, exp, device, exp_round, 'raw')\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            exp_files = [\"\", \"\", \"\", \"\"] # ack_ul_sent_raw_file, ack_ul_rcv_raw_file, ack_dl_sent_raw_file, ack_dl_rcv_raw_file\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    numbers = file.split(\"_\")[3]\n",
    "                    pers = file.split(\"_\")[4]\n",
    "                    if str(ports[0]) in numbers:\n",
    "                        if pers.split(\".\")[0] == \"client\":\n",
    "                            exp_files[1] = os.path.join(root, file)\n",
    "                        elif pers.split(\".\")[0] == \"server\":\n",
    "                            exp_files[0] = os.path.join(root, file)\n",
    "                    if str(ports[1]) in numbers:\n",
    "                        if pers.split(\".\")[0] == \"client\":\n",
    "                            exp_files[2] = os.path.join(root, file)\n",
    "                        elif pers.split(\".\")[0] == \"server\":\n",
    "                            exp_files[3] = os.path.join(root, file)\n",
    "            exp_files_list.append(exp_files)\n",
    "    return exp_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp_file_path_raw_dict = {}\n",
    "for exp in exps:\n",
    "    for date in dates:\n",
    "        for device in devices:\n",
    "            exp_raw_files = find_raw_files(database, date, exp, device)\n",
    "            if len(exp_raw_files) != 0:\n",
    "                if exp not in exp_file_path_raw_dict:\n",
    "                    exp_file_path_raw_dict[exp] = []\n",
    "                for files in exp_raw_files:\n",
    "                    print(files)\n",
    "                    exp_file_path_raw_dict[exp].append(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp_file_path_raw_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def GetRawDf(sent_raw_df):\n",
    "    sent_pkt_raw_df = sent_raw_df[(sent_raw_df['name'] == 'transport:p_sent')]\n",
    "    sent_ack_raw_df = sent_pkt_raw_df[(sent_pkt_raw_df['name'] == 'transport:p_sent') & (sent_pkt_raw_df['data'].str.contains(\"'fr_t': 'ack'\"))]\n",
    "    rcv_pkt_raw_df = sent_raw_df[(sent_raw_df['name'] == 'transport:p_rcv')]\n",
    "    return sent_pkt_raw_df, sent_ack_raw_df, rcv_pkt_raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "all_ul_ack_raw_file_len = {}\n",
    "all_dl_ack_raw_file_len = {}\n",
    "for exp in exps:\n",
    "    exp_ul_ack_raw_file_len = []\n",
    "    exp_dl_ack_raw_file_len = []\n",
    "    for sent_raw_files in exp_file_path_raw_dict[exp]:\n",
    "        ul_sent_raw_df = pd.read_csv(sent_raw_files[0], sep=',')\n",
    "        ul_sent_pkt_raw_df, ul_sent_ack_raw_df, ul_rcv_pkt_raw_df = GetRawDf(ul_sent_raw_df)\n",
    "        exp_ul_ack_raw_file_len.append([len(ul_sent_ack_raw_df), len(ul_sent_pkt_raw_df), len(ul_rcv_pkt_raw_df), (len(ul_sent_ack_raw_df) / len(ul_rcv_pkt_raw_df)) * 100])\n",
    "        dl_sent_raw_df = pd.read_csv(sent_raw_files[2], sep=',')\n",
    "        dl_sent_pkt_raw_df, dl_sent_ack_raw_df, dl_rcv_pkt_raw_df = GetRawDf(dl_sent_raw_df)\n",
    "        exp_dl_ack_raw_file_len.append([len(dl_sent_ack_raw_df), len(dl_sent_pkt_raw_df), len(dl_rcv_pkt_raw_df), (len(dl_sent_ack_raw_df) / len(dl_rcv_pkt_raw_df)) * 100])\n",
    "    all_ul_ack_raw_file_len[exp] = exp_ul_ack_raw_file_len\n",
    "    all_dl_ack_raw_file_len[exp] = exp_dl_ack_raw_file_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "all_ul_ack_raw_file_len\n",
    "for exp in exps:\n",
    "    sent_ack_cnt = 0\n",
    "    sent_ack_per_sec = 0\n",
    "    sent_ack_interval = 0\n",
    "    for row in all_ul_ack_raw_file_len[exp][0]:\n",
    "        sent_ack_cnt += all_ul_ack_raw_file_len[exp][0][0]\n",
    "    sent_ack_per_sec = sent_ack_cnt / (exp_duration * len(devices))\n",
    "    sent_ack_interval = 1000 / sent_ack_per_sec\n",
    "    print(\"UL:\", exp, sent_ack_cnt, f\"{sent_ack_interval}ms\", sent_ack_per_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "all_dl_ack_raw_file_len\n",
    "for exp in exps:\n",
    "    sent_ack_cnt = 0\n",
    "    sent_ack_per_sec = 0\n",
    "    sent_ack_interval = 0\n",
    "    for row in all_dl_ack_raw_file_len[exp][0]:\n",
    "        sent_ack_cnt += all_dl_ack_raw_file_len[exp][0][0]\n",
    "    sent_ack_per_sec = sent_ack_cnt / (exp_duration * len(devices))\n",
    "    sent_ack_interval = 1000 / sent_ack_per_sec\n",
    "    print(\"DL:\", exp, sent_ack_cnt, f\"{sent_ack_interval}ms\", sent_ack_per_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for exp in exps:\n",
    "    ul_exp_ack_overhead = [sublist[3] for sublist in all_ul_ack_raw_file_len[exp] if len(sublist) > 2]\n",
    "    ul_exp_ack_overhead_sum = sum(ul_exp_ack_overhead)\n",
    "    ul_exp_ack_overhead_cnt = len(all_ul_ack_raw_file_len[exp])\n",
    "    exp_avg_ul_ack_overhead = ul_exp_ack_overhead_sum / ul_exp_ack_overhead_cnt if ul_exp_ack_overhead_cnt != 0 else 0\n",
    "    print(exp, \"ul\", exp_avg_ul_ack_overhead)\n",
    "    dl_exp_ack_overhead = [sublist[3] for sublist in all_dl_ack_raw_file_len[exp] if len(sublist) > 2]\n",
    "    dl_exp_ack_overhead_sum = sum(dl_exp_ack_overhead)\n",
    "    dl_exp_ack_overhead_cnt = len(all_dl_ack_raw_file_len[exp])\n",
    "    exp_avg_dl_ack_overhead = dl_exp_ack_overhead_sum / dl_exp_ack_overhead_cnt if dl_exp_ack_overhead_cnt != 0 else 0\n",
    "    print(exp, \"dl\", exp_avg_dl_ack_overhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def plot_avg_ack_overhead(exps, all_ul_ack_raw_file_len, all_dl_ack_raw_file_len):\n",
    "    ul_averages = []\n",
    "    dl_averages = []\n",
    "    \n",
    "    for exp in exps:\n",
    "        # Calculate UL average ACK overhead\n",
    "        ul_exp_ack_overhead = [sublist[3] for sublist in all_ul_ack_raw_file_len[exp] if len(sublist) > 2]\n",
    "        ul_exp_ack_overhead_sum = sum(ul_exp_ack_overhead)\n",
    "        ul_exp_ack_overhead_cnt = len(all_ul_ack_raw_file_len[exp])\n",
    "        exp_avg_ul_ack_overhead = ul_exp_ack_overhead_sum / ul_exp_ack_overhead_cnt if ul_exp_ack_overhead_cnt != 0 else 0\n",
    "        ul_averages.append(exp_avg_ul_ack_overhead)\n",
    "        \n",
    "        # Calculate DL average ACK overhead\n",
    "        dl_exp_ack_overhead = [sublist[3] for sublist in all_dl_ack_raw_file_len[exp] if len(sublist) > 2]\n",
    "        dl_exp_ack_overhead_sum = sum(dl_exp_ack_overhead)\n",
    "        dl_exp_ack_overhead_cnt = len(all_dl_ack_raw_file_len[exp])\n",
    "        exp_avg_dl_ack_overhead = dl_exp_ack_overhead_sum / dl_exp_ack_overhead_cnt if dl_exp_ack_overhead_cnt != 0 else 0\n",
    "        dl_averages.append(exp_avg_dl_ack_overhead)\n",
    "    \n",
    "    # Plotting\n",
    "    x = range(len(exps))\n",
    "    width = 0.35  # width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x, ul_averages, width, label='UL Average ACK Overhead')\n",
    "    ax.bar([i + width for i in x], dl_averages, width, label='DL Average ACK Overhead')\n",
    "\n",
    "    ax.set_xlabel('Experiments')\n",
    "    ax.set_ylabel('Average ACK Overhead')\n",
    "    ax.set_title('Average ACK Overhead for UL and DL')\n",
    "    ax.set_xticks([i + width/2 for i in x])\n",
    "    ax.set_xticklabels(exps)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plot_avg_ack_overhead(exps, all_ul_ack_raw_file_len, all_dl_ack_raw_file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAckInfo(df):\n",
    "    df = df['data']\n",
    "    acked_ranges_list = []\n",
    "    ack_delay_list = []\n",
    "    ecn_list = []\n",
    "    # print(acked_ranges_series.iloc[0])\n",
    "    for i in range(len(df)):\n",
    "        try: \n",
    "            s = df.iloc[i]\n",
    "            data_dict = json.loads(s.replace(\"\\'\", \"\\\"\"))\n",
    "            for frame in data_dict['frames']:\n",
    "                if 'acked_ranges' in frame:\n",
    "                    for range_entry in frame['acked_ranges']:\n",
    "                        acked_ranges = range_entry\n",
    "            for frame in data_dict['frames']:\n",
    "                if 'ack_delay' in frame:\n",
    "                    ack_delay = frame['ack_delay']\n",
    "                    ack_delay_list.append(ack_delay)\n",
    "                if 'ce' in frame:\n",
    "                    if frame['ce'] != 0:\n",
    "                        ecn_list.append(True)\n",
    "                    else:\n",
    "                        ecn_list.append(False)\n",
    "            # Extract 'acked_ranges' from all frames\n",
    "            acked_ranges = [range_entry for frame in data_dict['frames'] if 'acked_ranges' in frame for range_entry in frame['acked_ranges']]\n",
    "            acked_ranges_list.append(acked_ranges)\n",
    "            # TODO: add ack_delay & ecn\n",
    "            \n",
    "        except:\n",
    "            print(s, i)\n",
    "            break\n",
    "\n",
    "    acked_ranges_df = pd.DataFrame({\"acked_ranges\": acked_ranges_list})\n",
    "    ack_delay_df = pd.DataFrame({\"ack_delay\": ack_delay_list})\n",
    "    ecn_df = pd.DataFrame({\"ecn\": ecn_list})\n",
    "\n",
    "    ack_info_df = pd.concat([acked_ranges_df, ack_delay_df, ecn_df], axis=1)\n",
    "    ack_info_df = ack_info_df.reset_index(drop=True)\n",
    "\n",
    "    return ack_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAckedRanges(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Iterate over rows in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        ranges = row['acked_ranges']\n",
    "\n",
    "        # If ranges is a list (and not empty), plot vertical lines\n",
    "        if isinstance(ranges, list):\n",
    "            for value in ranges:\n",
    "                if len(value) < 2:\n",
    "                    plt.plot([index, index], [value[0], value[0]], color='b', linestyle='-', alpha=0.7)\n",
    "                else:\n",
    "                    plt.plot([index, index], [value[0], value[1]], color='b', linestyle='-', alpha=0.7)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Row Index')\n",
    "    plt.ylabel('Acked Ranges')\n",
    "    plt.title('Vertical Lines Representing Acked Ranges')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check ACK packet freq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ack2_dl_delay = ack2_dl_sent_df['ack_delay'].mean()\n",
    "# mean_ack2_ul_delay = ack2_ul_sent_df['ack_delay'].mean()\n",
    "# print(mean_ack2_dl_delay)\n",
    "# ack2_dl_sent_df.iloc[100000:100010]['acked_ranges']\n",
    "# print(mean_ack2_ul_delay)\n",
    "# ack2_ul_sent_df.iloc[100000:100010]['acked_ranges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ack10_dl_delay = ack10_dl_sent_df['ack_delay'].mean()\n",
    "# mean_ack10_ul_delay = ack10_ul_sent_df['ack_delay'].mean()\n",
    "# print(mean_ack10_dl_delay)\n",
    "# ack10_dl_sent_df.iloc[100000:100010]['acked_ranges']\n",
    "# print(mean_ack10_ul_delay)\n",
    "# ack10_ul_sent_df.iloc[100000:100010]['acked_ranges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ack15_dl_delay = ack15_dl_sent_df['ack_delay'].mean()\n",
    "# mean_ack15_ul_delay = ack15_ul_sent_df['ack_delay'].mean()\n",
    "# print(mean_ack15_dl_delay)\n",
    "# print(ack15_dl_sent_df.iloc[100000:100010]['acked_ranges'])\n",
    "# print(mean_ack15_ul_delay)\n",
    "# print(ack15_ul_sent_df.iloc[100000:100010]['acked_ranges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodput ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def find_ul_sent_file(database, date, exp, device):\n",
    "    ul_files = []\n",
    "    exp_rounds, exp_list = exps[exp]\n",
    "    ports = device_to_port.get(device, [])\n",
    "    for exp_round in exp_list:\n",
    "        folder_path = os.path.join(database, date, exp, device, exp_round, 'data')\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.startswith(\"ul_processed_sent\"):\n",
    "                    ul_files.append(os.path.join(root, file))\n",
    "                    break  # Exit the inner loop once the port is found\n",
    "    return ul_files\n",
    "\n",
    "def find_dl_sent_file(database, date, exp, device):\n",
    "    dl_files = []\n",
    "    exp_rounds, exp_list = exps[exp]\n",
    "    ports = device_to_port.get(device, [])\n",
    "    for exp_round in exp_list:\n",
    "        folder_path = os.path.join(database, date, exp, device, exp_round, 'data')\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if \"dl_processed_sent\" in file:\n",
    "                    dl_files.append(os.path.join(root, file))\n",
    "                    break  # Exit the inner loop once the port is found\n",
    "    return dl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def calculate_goodput(sent_df):\n",
    "    df_copy = sent_df.copy()\n",
    "    df_copy.set_index(['packet_number', 'offset'], inplace=True)\n",
    "\n",
    "    # Group by 'offset' and count occurrences\n",
    "    offset_counts = df_copy.groupby(level='offset').size()\n",
    "\n",
    "    # Identify repeated and not repeated offsets\n",
    "    repeated_offsets = offset_counts[offset_counts > 1].index\n",
    "    not_repeated_offsets = offset_counts[offset_counts == 1].index\n",
    "\n",
    "    goodput = len(not_repeated_offsets)*100 / len(df_copy)\n",
    "    return goodput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def plot_avg_goodput(avg_ul_goodput, avg_dl_goodput):\n",
    "    # Extract experiment names and average goodput values\n",
    "    exp_names_ul = list(avg_ul_goodput.keys())\n",
    "    avg_ul_values = list(avg_ul_goodput.values())\n",
    "\n",
    "    exp_names_dl = list(avg_dl_goodput.keys())\n",
    "    avg_dl_values = list(avg_dl_goodput.values())\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot Uplink Goodput\n",
    "    plt.plot(exp_names_ul, avg_ul_values, marker='o', label='Uplink Goodput')\n",
    "\n",
    "    # Plot Downlink Goodput\n",
    "    plt.plot(exp_names_dl, avg_dl_values, marker='o', label='Downlink Goodput')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Experiment')\n",
    "    plt.ylabel('Goodput (%)')\n",
    "    plt.title('Average Uplink and Downlink Goodput')\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "all_ul_goodput = {}\n",
    "all_dl_goodput = {}\n",
    "# Iterate over dates, exps, and devices\n",
    "for exp in exps:\n",
    "    exp_ul_goodput = []\n",
    "    exp_dl_goodput = []\n",
    "    for date in dates:\n",
    "        for device in devices:\n",
    "            ul_sent_files = find_ul_sent_file(database, date, exp, device)\n",
    "            dl_sent_files = find_dl_sent_file(database, date, exp, device)\n",
    "            for ul_sent_file in ul_sent_files:\n",
    "                ul_sent_df = pd.read_csv(ul_sent_file, sep='@')\n",
    "                exp_ul_goodput.append(calculate_goodput(ul_sent_df))\n",
    "            for dl_sent_file in dl_sent_files:\n",
    "                dl_sent_df = pd.read_csv(dl_sent_file, sep='@')\n",
    "                exp_dl_goodput.append(calculate_goodput(dl_sent_df))\n",
    "\n",
    "    all_ul_goodput[exp] = exp_ul_goodput\n",
    "    all_dl_goodput[exp] = exp_dl_goodput\n",
    "\n",
    "avg_ul_goodput = {}\n",
    "avg_dl_goodput = {}\n",
    "# Calculate average uplink and downlink goodput for each experiment\n",
    "for exp, ul_goodput_list in all_ul_goodput.items():\n",
    "    avg_ul_goodput[exp] = sum(ul_goodput_list) / len(ul_goodput_list)\n",
    "for exp, dl_goodput_list in all_dl_goodput.items():\n",
    "    avg_dl_goodput[exp] = sum(dl_goodput_list) / len(dl_goodput_list)\n",
    "\n",
    "print(\"Average Uplink Goodput:\")\n",
    "print(avg_ul_goodput)\n",
    "print(\"\\nAverage Downlink Goodput:\")\n",
    "print(avg_dl_goodput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plot_avg_goodput(avg_ul_goodput, avg_dl_goodput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def find_stats_files(database, date, exp, device):\n",
    "    ul_files = []\n",
    "    dl_files = []\n",
    "    exp_rounds, exp_list = exps[exp]\n",
    "    ports = device_to_port.get(device, [])\n",
    "    for exp_round in exp_list:\n",
    "        folder_path = os.path.join(database, date, exp, device, exp_round, 'statistics')\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.startswith(\"ul_statistics\"):\n",
    "                    ul_files.append(os.path.join(root, file))\n",
    "                if file.startswith(\"dl_statistics\"):\n",
    "                    dl_files.append(os.path.join(root, file))\n",
    "    return ul_files, dl_files\n",
    "\n",
    "def calculate_avg_stats(df):\n",
    "    avg_total_packets = int(df['total_packets'].mean())\n",
    "    avg_data_packets  = int(df['total_data_packets'].mean())\n",
    "    avg_original_pkl  = int(df['original_pkl'].mean())\n",
    "    avg_reordering_threshold = int(df['reordering_threshold'].mean())\n",
    "    avg_time_threshold = int(df['time_threshold'].mean())\n",
    "    avg_real_pkl = int(df['reordering_threshold'].mean()) + int(df['time_threshold'].mean())\n",
    "    \n",
    "    return {\"total_packets\": avg_total_packets,\n",
    "            \"total_data_packets\": avg_data_packets,\n",
    "            \"original_pkl\": avg_original_pkl,\n",
    "            \"reordering_threshold\": avg_reordering_threshold,\n",
    "            \"time_threshold\": avg_time_threshold,\n",
    "            \"real_pkl\": avg_real_pkl,\n",
    "            \"exec_reordering\": int(df['exec_reordering'].mean()),\n",
    "            \"exec_time\": int(df['exec_time'].mean()),\n",
    "            \"exec_lat\": int(df['exec_reordering'].mean()) + int(df['exec_time'].mean()),\n",
    "            \"reordering_pkl_rate(%)\": 0 if avg_real_pkl == 0 else avg_reordering_threshold*100 / avg_real_pkl,\n",
    "            \"time_pkl_rate(%)\": 0 if avg_real_pkl == 0 else avg_time_threshold*100 / avg_real_pkl,\n",
    "            \"real_pkl_rate(%)\": 0 if avg_original_pkl == 0 else avg_real_pkl*100 / avg_original_pkl,\n",
    "            \"original_packet_loss_rate(%)\": avg_original_pkl*100 / avg_total_packets,\n",
    "            \"adjusted_packet_loss_rate(%)\": avg_real_pkl*100 / avg_total_packets\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "all_avg_ul_stats = {}\n",
    "all_avg_dl_stats = {}\n",
    "# Iterate over dates, exps, and devices\n",
    "for exp in exps:\n",
    "    exp_ul_stats_files = []\n",
    "    exp_dl_stats_files = []\n",
    "    for date in dates:\n",
    "        for device in devices:\n",
    "            ul_stats_files, dl_stats_files = find_stats_files(database, date, exp, device)\n",
    "            exp_ul_stats_files.extend(ul_stats_files)\n",
    "            exp_dl_stats_files.extend(dl_stats_files)\n",
    "    stats = []\n",
    "    # Iterate over each file path\n",
    "    for file_path in exp_ul_stats_files:\n",
    "        # Read CSV file into a DataFrame and append it to the list\n",
    "        df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "        stats.append(df)\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    exp_ul_stats = pd.concat(stats, ignore_index=True)\n",
    "\n",
    "    stats = []\n",
    "    for file_path in exp_dl_stats_files:\n",
    "        df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "        stats.append(df)\n",
    "    exp_dl_stats = pd.concat(stats, ignore_index=True)\n",
    "\n",
    "    all_avg_ul_stats[exp] = calculate_avg_stats(exp_ul_stats)\n",
    "    all_avg_dl_stats[exp] = calculate_avg_stats(exp_dl_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_ul_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_dl_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Calculations\n",
    "for key, value in all_avg_ul_stats.items():\n",
    "    total_data_packets = value['total_data_packets']\n",
    "    original_packet_loss_rate = value['original_packet_loss_rate(%)']\n",
    "    # Calculate total throughput\n",
    "    total_throughput = (total_data_packets * data_len) / time_data\n",
    "    total_goodput = (1 - original_packet_loss_rate) * total_throughput\n",
    "    # Add results to dictionary\n",
    "    all_avg_ul_stats[key]['total_throughput'] = total_throughput\n",
    "    all_avg_ul_stats[key]['total_goodput'] = total_goodput\n",
    "for key, value in all_avg_dl_stats.items():\n",
    "    total_data_packets = value['total_data_packets']\n",
    "    original_packet_loss_rate = value['original_packet_loss_rate(%)']\n",
    "    # Calculate total throughput\n",
    "    total_throughput = (total_data_packets * data_len) / time_data\n",
    "    total_goodput = (1 - original_packet_loss_rate) * total_throughput\n",
    "    # Add results to dictionary\n",
    "    all_avg_dl_stats[key]['total_throughput'] = total_throughput\n",
    "    all_avg_dl_stats[key]['total_goodput'] = total_goodput\n",
    "\n",
    "# Print results\n",
    "for key, value in all_avg_ul_stats.items():\n",
    "    print(f\"{key}: UL Total Throughput = {value['total_throughput']}, UL Total Goodput = {value['total_goodput']}\")\n",
    "for key, value in all_avg_dl_stats.items():\n",
    "    print(f\"{key}: DL Total Throughput = {value['total_throughput']}, DL Total Goodput = {value['total_goodput']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Assume all_avg_ul_stats and all_avg_dl_stats are already defined\n",
    "\n",
    "# Define the baseline key\n",
    "baseline_key = 'QUIC-ack2'\n",
    "\n",
    "# Extract baseline values for UL\n",
    "baseline_ul_throughput = all_avg_ul_stats[baseline_key]['total_throughput']\n",
    "baseline_ul_goodput = all_avg_ul_stats[baseline_key]['total_goodput']\n",
    "\n",
    "# Extract baseline values for DL\n",
    "baseline_dl_throughput = all_avg_dl_stats[baseline_key]['total_throughput']\n",
    "baseline_dl_goodput = all_avg_dl_stats[baseline_key]['total_goodput']\n",
    "\n",
    "# Calculate and print increases for UL\n",
    "print(\"UL Increases:\")\n",
    "for key, value in all_avg_ul_stats.items():\n",
    "    if key != baseline_key:\n",
    "        ul_throughput_increase = (value['total_throughput'] - baseline_ul_throughput) / baseline_ul_throughput * 100\n",
    "        ul_goodput_increase = (value['total_goodput'] - baseline_ul_goodput) / baseline_ul_goodput * 100\n",
    "        print(f\"{key}: UL Throughput Increase = {ul_throughput_increase:.2f}%, UL Goodput Increase = {ul_goodput_increase:.2f}%\")\n",
    "\n",
    "# Calculate and print increases for DL\n",
    "print(\"\\nDL Increases:\")\n",
    "for key, value in all_avg_dl_stats.items():\n",
    "    if key != baseline_key:\n",
    "        dl_throughput_increase = (value['total_throughput'] - baseline_dl_throughput) / baseline_dl_throughput * 100\n",
    "        dl_goodput_increase = (value['total_goodput'] - baseline_dl_goodput) / baseline_dl_goodput * 100\n",
    "        print(f\"{key}: DL Throughput Increase = {dl_throughput_increase:.2f}%, DL Goodput Increase = {dl_goodput_increase:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def plotThroughputGoodput(stats, ul_dl):\n",
    "    # Extract keys, throughput, and goodput\n",
    "    keys = list(stats.keys())\n",
    "    throughput = [stats[key]['total_throughput'] for key in keys]\n",
    "    goodput = [stats[key]['total_goodput'] for key in keys]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    bar_width = 0.35\n",
    "    index = range(len(keys))\n",
    "    \n",
    "    # Throughput and Goodput bars\n",
    "    plt.bar(index, throughput, bar_width, label=f'{ul_dl} Throughput', alpha=0.7, color='b')\n",
    "    plt.bar([i + bar_width for i in index], goodput, bar_width, label=f'{ul_dl} Goodput', alpha=0.7, color='g')\n",
    "    \n",
    "    # Labels and Title\n",
    "    plt.xlabel('Experiments')\n",
    "    plt.ylabel('Throughput (Mbps)')\n",
    "    plt.title(f'Throughput and Goodput for {ul_dl}')\n",
    "    plt.xticks([i + bar_width / 2 for i in index], keys)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plotThroughputGoodput(all_avg_ul_stats, \"UL\")  # For UL stats\n",
    "plotThroughputGoodput(all_avg_dl_stats, \"DL\")  # For DL stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
